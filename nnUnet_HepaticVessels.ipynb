{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tVYHFhnfk2nE"
      },
      "source": [
        "## Checking Resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "333PEztf6FI-",
        "outputId": "f1396169-19a9-489a-a490-db96539279ba"
      },
      "outputs": [],
      "source": [
        "# This will give details about the CUDA environment\n",
        "!nvcc --version\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEAyFwH-ROW8",
        "outputId": "5624242e-08ee-4ed2-8565-175b41ee3536"
      },
      "outputs": [],
      "source": [
        "#for colab users only - mounting the drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount = False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Specify The Base Directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJBLGI17DC-O"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "base_dir = '/content/drive/My Drive/vessels'\n",
        "os.chdir(base_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Preparing The Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCnE_wgsCauq"
      },
      "outputs": [],
      "source": [
        "#installing pytorch\n",
        "%pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "# installing nnunet\n",
        "%pip install nnunetv2\n",
        "\n",
        "# %pip install packaging\n",
        "\n",
        "# #cloning repository\n",
        "# !git clone https://github.com/MIC-DKFZ/nnUNet.git\n",
        "\n",
        "# !git clone https://github.com/NVIDIA/apex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HVDXJPoGB5S6",
        "outputId": "6db51afc-f777-4d81-9004-4587bd801f41"
      },
      "outputs": [],
      "source": [
        "# respository_dir = os.path.join(base_dir,'nnUNet')\n",
        "# os.chdir(respository_dir)\n",
        "\n",
        "# !pip install -e .\n",
        "# !pip install --upgrade git+https://github.com/nanohanno/hiddenlayer.git@bugfix/get_trace_graph#egg=hiddenlayer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nt0aVu7x5sX-",
        "outputId": "95a36c9e-13a1-4728-bcf6-2ba5e9d17c45"
      },
      "outputs": [],
      "source": [
        "os.chdir(base_dir)\n",
        "\n",
        "import shutil\n",
        "from collections import OrderedDict\n",
        "import json\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import nibabel as nib\n",
        "\n",
        "import os\n",
        "\n",
        "if os.getcwd()==base_dir:\n",
        "    print('We are in the correct directory')\n",
        "else:\n",
        "    print(\"Run set base directory step again, then check to verify.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Prepare Directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d78Fh5dbCaqu"
      },
      "outputs": [],
      "source": [
        "def make_if_dont_exist(folder_path,overwrite=False):\n",
        "    \"\"\"\n",
        "    creates a folder if it does not exists\n",
        "    input:\n",
        "    folder_path : relative path of the folder which needs to be created\n",
        "    over_write :(default: False) if True overwrite the existing folder\n",
        "    \"\"\"\n",
        "    if os.path.exists(folder_path):\n",
        "\n",
        "        if not overwrite:\n",
        "            print(f'{folder_path} exists.')\n",
        "        else:\n",
        "\n",
        "            print(f\"{folder_path} overwritten\")\n",
        "            shutil.rmtree(folder_path)\n",
        "            os.makedirs(folder_path)\n",
        "\n",
        "    else:\n",
        "      os.makedirs(folder_path)\n",
        "      print(f\"{folder_path} created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NF4NZt5XDxVR"
      },
      "outputs": [],
      "source": [
        "\n",
        "task_name = 'Dataset101_HepVes' #task name\n",
        "nnunet_dir = \"nnUNet/nnunetv2/nnUNet_raw\"\n",
        "task_folder_name = os.path.join(nnunet_dir,task_name)\n",
        "train_image_dir = os.path.join(task_folder_name,'imagesTr')\n",
        "train_label_dir = os.path.join(task_folder_name,'labelsTr')\n",
        "test_dir = os.path.join(task_folder_name,'imagesTs')\n",
        "test_label_dir = os.path.join(task_folder_name,'labelsTs')\n",
        "main_dir = os.path.join(base_dir,'nnUNet/nnunetv2')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GU7jg2W8EgVb",
        "outputId": "80258908-1bcc-44c8-c385-f10b0401fa40"
      },
      "outputs": [],
      "source": [
        "make_if_dont_exist(task_folder_name,overwrite = False)\n",
        "make_if_dont_exist(os.path.join(main_dir,'nnUNet_results'))\n",
        "make_if_dont_exist(os.path.join(main_dir,'nnUNet_preprocessed'))\n",
        "make_if_dont_exist(os.path.join(main_dir,'nnUNet_preprocessed_test'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Copy Data to desired Directory**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uYPnnQOjflsw"
      },
      "outputs": [],
      "source": [
        "# import os\n",
        "# import shutil\n",
        "\n",
        "# source_folder = '/content/drive/MyDrive/Colab Notebook/nnUNet/nnunetv2/nnUNet_raw/Dataset101_HepVes/imagesTr'\n",
        "# destination_folder = '/content/drive/MyDrive/vessels/nnUNet/nnunetv2/nnUNet_raw/Dataset101_HepVes/imagesTs'\n",
        "\n",
        "# # List all files in the source folder\n",
        "# files = [f for f in os.listdir(source_folder) if os.path.isfile(os.path.join(source_folder, f))]\n",
        "\n",
        "# # Sort the files alphabetically\n",
        "# files.sort()\n",
        "\n",
        "# # Copy the first 260 files to the destination folder\n",
        "# for file in files[260:]:\n",
        "#     source_file_path = os.path.join(source_folder, file)\n",
        "#     destination_file_path = os.path.join(destination_folder, file)\n",
        "#     shutil.copy(source_file_path, destination_file_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Q1e7Pq3pkDl"
      },
      "source": [
        "**Creating Environement Variables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tDVIhPZE8Em"
      },
      "outputs": [],
      "source": [
        "os.environ['nnUNet_raw'] = os.path.join(main_dir,'nnUNet_raw')\n",
        "os.environ['nnUNet_preprocessed'] = os.path.join(main_dir,'nnUNet_preprocessed')\n",
        "os.environ['nnUNet_preprocessed'] = os.path.join(main_dir,'nnUNet_preprocessed_test')\n",
        "os.environ['nnUNet_results'] = os.path.join(main_dir,'nnUNet_results')\n",
        "os.chdir(base_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsefoHGSp0P2"
      },
      "source": [
        "**Checking Training Files and Labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yIerkP2Fg-s"
      },
      "outputs": [],
      "source": [
        "# train_files = os.listdir(train_image_dir)\n",
        "# label_files = os.listdir(train_label_dir)\n",
        "# test_files = os.listdir(test_dir)\n",
        "# print(\"train image files:\",len(train_files))\n",
        "# print(\"train label files:\",len(train_files))\n",
        "# print(\"Matches:\",len(set(train_files).intersection(set(label_files))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0JcB25akYFwX"
      },
      "source": [
        "**One Time Run therefore commented**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v9uyK4G-Srz8"
      },
      "outputs": [],
      "source": [
        "# for i in range(len(train_files)):\n",
        "#   file_name=train_files[i]\n",
        "#   name, extension = os.path.splitext(file_name)\n",
        "#   name, extension = os.path.splitext(name)\n",
        "#   new_name=name+\"_0000.nii.gz\"\n",
        "#   src=os.path.join(train_image_dir,file_name)\n",
        "#   dst=os.path.join(train_image_dir,new_name)\n",
        "#   os.rename(src, dst)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# for i in range(len(test_files)):\n",
        "#   file_name=test_files[i]\n",
        "#   name, extension = os.path.splitext(file_name)\n",
        "#   name, extension = os.path.splitext(name)\n",
        "#   new_name=name+\"_0000.nii.gz\"\n",
        "#   src=os.path.join(test_dir,file_name)\n",
        "#   dst=os.path.join(test_dir,new_name)\n",
        "#   os.rename(src, dst)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLninMsTYl7y"
      },
      "source": [
        "**Create and Update Dataset.json(260 training and 43 test)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "19KpEHdubVVn"
      },
      "outputs": [],
      "source": [
        "# overwrite_json_file = True #make it True if you want to overwrite the dataset.json file in Task_folder\n",
        "# json_file_exist = False\n",
        "\n",
        "# if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
        "#     print('dataset.json already exist!')\n",
        "#     json_file_exist = True\n",
        "\n",
        "# if json_file_exist==False or overwrite_json_file:\n",
        "\n",
        "#     json_dict = OrderedDict()\n",
        "#     json_dict['name'] = task_name\n",
        "#     json_dict['description'] = \"Hepatic Vessels and Tumour Segmentation\"\n",
        "#     json_dict['tensorImageSize'] = \"3D\"\n",
        "#     json_dict['reference'] = \"Memorial Sloan Kettering Cancer Center\"\n",
        "#     json_dict['licence'] = \"CC-BY-SA 4.0\"\n",
        "#     json_dict['release'] = \"0.0\"\n",
        "\n",
        "#     #you may mention more than one modality\n",
        "#     json_dict['channel_names'] = {\n",
        "#         \"0\": \"CT\"\n",
        "#     }\n",
        "#     #labels+1 should be mentioned for all the labels in the dataset\n",
        "#     json_dict['labels'] = {\n",
        "#         \"background\":0,\n",
        "#         \"Vessel\":1,\n",
        "#         \"Tumour\":2\n",
        "#     }\n",
        "#     json_dict['file_ending'] = \".nii.gz\"\n",
        "\n",
        "#     train_ids = os.listdir(train_label_dir)\n",
        "#     test_ids = os.listdir(test_dir)\n",
        "#     json_dict['numTraining'] = len(train_ids)\n",
        "#     json_dict['numTest'] = len(test_ids)\n",
        "\n",
        "#     #no modality in train image and labels in dataset.json\n",
        "#     json_dict['training'] = [{'image': \"./imagesTr/%s\" % i, \"label\": \"./labelsTr/%s\" % i} for i in train_ids]\n",
        "\n",
        "#     #removing the modality from test image name to be saved in dataset.json\n",
        "#     json_dict['test'] = [\"./imagesTs/%s\" % (i[:i.find(\"_0000\")]+'.nii.gz') for i in test_ids]\n",
        "\n",
        "#     with open(os.path.join(task_folder_name,\"dataset.json\"), 'w') as f:\n",
        "#         json.dump(json_dict, f, indent=4, sort_keys=True)\n",
        "\n",
        "#     if os.path.exists(os.path.join(task_folder_name,'dataset.json')):\n",
        "#         if json_file_exist==False:\n",
        "#             print('dataset.json created!')\n",
        "#         else:\n",
        "#             print('dataset.json overwritten!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2tEEI7o-s3u"
      },
      "source": [
        "## Train Dataset Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JG2d2YNn-vTZ"
      },
      "outputs": [],
      "source": [
        "# #visualizing some of the training images and labels\n",
        "# # (re-run to see random pick-ups)\n",
        "# # only maximum of first 5 slices are plotted\n",
        "# train_img_name = os.listdir(train_image_dir)[np.random.randint(0,5)]\n",
        "# train_img = np.array(nib.load(os.path.join(train_image_dir,train_img_name)).dataobj)[:,:,35:40]\n",
        "# train_label_name = train_img_name[:train_img_name.find('_0000.nii.gz')]+'.nii.gz'\n",
        "# train_label = np.array(nib.load(os.path.join(train_label_dir,train_label_name)).dataobj)[:,:,35:40]\n",
        "\n",
        "# print(train_img.shape,train_label.shape)\n",
        "\n",
        "# max_rows = 2\n",
        "# max_cols = train_img.shape[2]\n",
        "\n",
        "# fig, axes = plt.subplots(nrows=max_rows, ncols=max_cols, figsize=(20,8))\n",
        "# for idx in range(max_cols):\n",
        "#     axes[0, idx].axis(\"off\")\n",
        "#     axes[0, idx].set_title('Train Image'+str(idx+1))\n",
        "#     axes[0 ,idx].imshow(train_img[:,:,idx], cmap=\"gray\")\n",
        "# for idx in range(max_cols):\n",
        "#     axes[1, idx].axis(\"off\")\n",
        "#     axes[1, idx].set_title('Train Label'+str(idx+1))\n",
        "#     axes[1, idx].imshow(train_label[:,:,idx] , cmap=\"gray\")\n",
        "\n",
        "# plt.subplots_adjust(wspace=.1, hspace=.1)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOBrjYhR-svp"
      },
      "source": [
        "## Test Data Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WYJJTlPJ-9oo"
      },
      "outputs": [],
      "source": [
        "# #visualizing some of the test images\n",
        "# # (re-run to see random pick-ups)\n",
        "# # only maximum of first 5 slices are plotted\n",
        "\n",
        "# test_img_name = os.listdir(test_dir)[np.random.randint(0,40)]\n",
        "# test_img = np.array(nib.load(os.path.join(test_dir,test_img_name)).dataobj)[:,:,:5]\n",
        "\n",
        "# print(test_img.shape)\n",
        "\n",
        "# max_cols = test_img.shape[2]\n",
        "# max_rows = 1\n",
        "\n",
        "# fig, axes = plt.subplots(nrows=max_rows, ncols=max_cols, figsize=(20,20))\n",
        "# for idx in range(max_cols):\n",
        "#     axes[ idx].axis(\"off\")\n",
        "#     axes[ idx].set_title('Test Image'+str(idx))\n",
        "#     axes[ idx].imshow(test_img[:,:,idx], cmap=\"gray\")\n",
        "\n",
        "\n",
        "# plt.subplots_adjust(wspace=.1, hspace=.1)\n",
        "# plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Try working with apex**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yW6fkx-5Y-ZW"
      },
      "outputs": [],
      "source": [
        "# #colab users - mandatory\n",
        "# #local machine - once is sufficient\n",
        "# os.chdir('apex')\n",
        "# !pip3 install -v --no-cache-dir --global-option=\"--cpp_ext\" --global-option=\"--cuda_ext\" ./\n",
        "# os.chdir(base_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Renaming the training and testing data depending on the planing configurations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t1F1bxqQbMgT"
      },
      "outputs": [],
      "source": [
        "# don't run this cell anymore\n",
        "\n",
        "#import os\n",
        "\n",
        "# Paths to your labels directory\n",
        "#labels_dir = '/content/drive/MyDrive/Colab Notebook/nnUNet/nnunetv2/nnUNet_raw/Dataset101_HepVes/labelsTr'\n",
        "\n",
        "# The pattern to append to each label file name (before the extension)\n",
        "#pattern_to_append = '_0000_0000_0000_0000'\n",
        "\n",
        "# Get a list of all label files\n",
        "#label_files = os.listdir(labels_dir)\n",
        "\n",
        "# Loop through each label file\n",
        "#for label_file in label_files:\n",
        "    # Check if the label file ends with '.nii.gz' or '.nii' and split accordingly\n",
        "#    if label_file.endswith('.nii.gz'):\n",
        "#        base_name = label_file[:-7]  # Removes '.nii.gz' from the end\n",
        "#        extension = '.nii.gz'\n",
        "#    elif label_file.endswith('.nii'):\n",
        "#        base_name = label_file[:-4]  # Removes '.nii' from the end\n",
        "#        extension = '.nii'\n",
        "#    else:\n",
        "#        # If the file does not end with known extensions, skip it\n",
        "#        print(f\"Skipping unknown file type: {label_file}\")\n",
        "#        continue\n",
        "\n",
        "#    # Construct the new label filename with the pattern appended before the extension\n",
        "#    new_label_file = base_name + pattern_to_append + extension\n",
        "\n",
        "#    # Paths for the current and new label files\n",
        "#    current_label_path = os.path.join(labels_dir, label_file)\n",
        "#    new_label_path = os.path.join(labels_dir, new_label_file)\n",
        "\n",
        "    # Rename the label file\n",
        "#    os.rename(current_label_path, new_label_path)\n",
        "#    print(f'Renamed \"{label_file}\" to \"{new_label_file}\"')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6iGyIfPj5IT"
      },
      "outputs": [],
      "source": [
        "# one time then commented as it affects the files names permenantly *(don't run this cell any more)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#import os\n",
        "\n",
        "# Paths to your labels directory\n",
        "#labels_dir = '/content/drive/MyDrive/Colab Notebook/nnUNet/nnunetv2/nnUNet_raw/Dataset101_HepVes/labelsTr'\n",
        "\n",
        "# The pattern to remove from each label file name\n",
        "#pattern_to_remove = '_0000'\n",
        "\n",
        "# Get a list of all label files\n",
        "#label_files = os.listdir(labels_dir)\n",
        "\n",
        "# Loop through each label file\n",
        "#for label_file in label_files:\n",
        "    # Check if the label file ends with '.nii.gz' or '.nii' and split accordingly\n",
        "#    if label_file.endswith('.nii.gz'):\n",
        "#        base_name = label_file[:-7]  # Removes '.nii.gz' from the end\n",
        "#        extension = '.nii.gz'\n",
        "#    elif label_file.endswith('.nii'):\n",
        "#        base_name = label_file[:-4]  # Removes '.nii' from the end\n",
        "#        extension = '.nii'\n",
        "#    else:\n",
        "        # If the file does not end with known extensions, skip it\n",
        "#        print(f\"Skipping unknown file type: {label_file}\")\n",
        "#        continue\n",
        "\n",
        "    # Check if the file name contains the pattern and remove it\n",
        "#    if pattern_to_remove in base_name:\n",
        "#        # Create a new base name by replacing the pattern with an empty string\n",
        "#        new_base_name = base_name.replace(pattern_to_remove, '')\n",
        "        # Construct the new label filename without the pattern\n",
        "#        new_label_file = new_base_name + extension\n",
        "\n",
        "        # Paths for the current and new label files\n",
        "#        current_label_path = os.path.join(labels_dir, label_file)\n",
        "#        new_label_path = os.path.join(labels_dir, new_label_file)\n",
        "\n",
        "        # Rename the label file\n",
        "#        os.rename(current_label_path, new_label_path)\n",
        "#        print(f'Renamed \"{label_file}\" to \"{new_label_file}\"')\n",
        "#    else:\n",
        "#        print(f\"No pattern found in {label_file}, skipping rename.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset Preprocessing and Experiment Planning (Try Diffrent methods)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -> Method 1 (not the best for nnunetv2)\n",
        "\n",
        "# %pip install nnunet\n",
        "# os.chdir(main_dir)\n",
        "# !nnUNet_train 3d_fullres nnUNetTrainerV2 101 0\n",
        "# os.chdir(base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# -> Method 2\n",
        "\n",
        "# #running it from the experiment_planning folder to verify the path settings\n",
        "# os.chdir(main_dir)\n",
        "# !python experiment_planning/plan_and_preprocess_api.py -t 101 --verify_dataset_integrity\n",
        "# os.chdir(base_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ndco7nUET9l-"
      },
      "outputs": [],
      "source": [
        "# -> Method 3 (needs high computing resources)\n",
        "\n",
        "# nnUNetv2_plan_experiment -d 3 -pl nnUNetPlannerResEncM -gpu_memory_target 50 -overwrite_plans_name nnUNetResEncUNetPlans_50G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hxr4CsNiM5Jn"
      },
      "outputs": [],
      "source": [
        "# -> Work Just Fine after adjusting the configurations and organize and rename the files\n",
        "\n",
        "!nnUNetv2_plan_and_preprocess -d 101 --verify_dataset_integrity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QC20G94G-r56"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YnnZA6r8QsaW"
      },
      "outputs": [],
      "source": [
        "os.chdir(main_dir)\n",
        "\n",
        "!nnUNetv2_train 101 2d \"all\" -tr \"nnUNetTrainer_20epochs\"\n",
        "!nnUNetv2_train 101 3d_lowres \"all\" -tr \"nnUNetTrainer_20epochs\"\n",
        "\n",
        "os.chdir(base_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x3lLvVV-3em"
      },
      "source": [
        "## Models Predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tfg2ILputYyI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# result_dir_2d = os.path.join(main_dir,\"result_dir_2d\")\n",
        "# result_dir_lowers = os.path.join(main_dir,\"result_dir_lowers\")\n",
        "\n",
        "# make_if_dont_exist(result_dir_2d)\n",
        "# team_name = 'vessels' #make sure to change for your own team nam\n",
        "# #location where you want save your results, will be created if dont exist\n",
        "# os.chdir(main_dir)\n",
        "\n",
        "# !nnUNetv2_predict -h\n",
        "# !nnUNetv2_predict -i nnUNet_raw/Dataset101_HepVes/imagesTs -o result_dir_2d -d 101 -tr \"nnUNetTrainer_100epochs\" -c 2d -f \"all\"\n",
        "# !nnUNetv2_predict -i nnUNet_raw/Dataset101_HepVes/imagesTs -o result_dir_lowers -d 101 -tr \"nnUNetTrainer_100epochs\" -c 3d_lowres -f \"all\"\n",
        "# os.chdir(base_dir)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXrjQcAt-66N"
      },
      "source": [
        "**Displaying Predictions For the 2d configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "LDoq8f0pTCX0",
        "outputId": "f020c6fa-2b7a-48a5-9111-c2fb409d2c69"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories\n",
        "result_dir_2d = os.path.join(main_dir, \"result_dir_2d\")\n",
        "result_dir = os.path.join(main_dir, 'nnUNet_Prediction_Results', task_name)\n",
        "test_img_name = os.listdir(test_dir)[15]\n",
        "\n",
        "# Load test image, predicted image, and label\n",
        "test_img = np.array(nib.load(os.path.join(test_dir, test_img_name)).dataobj)\n",
        "mid = int(test_img.shape[2] / 2)\n",
        "test_img = test_img[:, :, mid:mid+5]\n",
        "\n",
        "predicted_img_name = test_img_name[:test_img_name.find('_0000.nii.gz')] + '.nii.gz'\n",
        "predicted_images = np.array(nib.load(os.path.join(result_dir_2d, predicted_img_name)).dataobj)[:, :, mid+10:mid+15]\n",
        "predicted_label = np.array(nib.load(os.path.join(test_label_dir, predicted_img_name)).dataobj)[:, :, mid+10:mid+15]\n",
        "\n",
        "# Display shapes\n",
        "print('Test Image Shape:', test_img.shape)\n",
        "print('Predicted Image Shape:', predicted_label.shape)\n",
        "\n",
        "# Define plot configuration\n",
        "max_rows = 3\n",
        "max_cols = test_img.shape[2]\n",
        "fig, axes = plt.subplots(nrows=max_rows, ncols=max_cols, figsize=(20, 8))\n",
        "\n",
        "# Plot images\n",
        "for idx in range(max_cols):\n",
        "    axes[0, idx].axis(\"off\")\n",
        "    axes[0, idx].set_title('Test Image ' + str(idx+1))\n",
        "    axes[0, idx].imshow(test_img[:, :, idx], cmap=\"gray\")\n",
        "\n",
        "for idx in range(max_cols):\n",
        "    axes[1, idx].axis(\"off\")\n",
        "    axes[1, idx].set_title('Test Prediction ' + str(idx+1))\n",
        "    axes[1, idx].imshow(predicted_images[:, :, idx], cmap=\"gray\")\n",
        "\n",
        "for idx in range(max_cols):\n",
        "    axes[2, idx].axis(\"off\")\n",
        "    axes[2, idx].set_title('Train Label ' + str(idx+1))\n",
        "    axes[2, idx].imshow(predicted_label[:, :, idx], cmap=\"gray\")\n",
        "\n",
        "# Adjust subplot spacing\n",
        "plt.subplots_adjust(wspace=.1, hspace=.4)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Displaying Predictions For the 3d_lowers configuration**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "0ORJEEVp7Dh0",
        "outputId": "99ea04a1-474f-494a-b217-f9b3b91c9477"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import nibabel as nib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define directories\n",
        "result_dir_lowers = os.path.join(main_dir, \"result_dir_lowers\")\n",
        "result_dir = os.path.join(main_dir, 'nnUNet_Prediction_Results', task_name)\n",
        "test_img_name = os.listdir(test_dir)[15]\n",
        "\n",
        "# Load test image, predicted image, and label\n",
        "test_img = np.array(nib.load(os.path.join(test_dir, test_img_name)).dataobj)\n",
        "mid = int(test_img.shape[2] / 2)\n",
        "test_img = test_img[:, :, mid:mid+5]\n",
        "\n",
        "predicted_img_name = test_img_name[:test_img_name.find('_0000.nii.gz')] + '.nii.gz'\n",
        "predicted_images = np.array(nib.load(os.path.join(result_dir_lowers, predicted_img_name)).dataobj)[:, :, mid+10:mid+15]\n",
        "predicted_label = np.array(nib.load(os.path.join(test_label_dir, predicted_img_name)).dataobj)[:, :, mid+10:mid+15]\n",
        "\n",
        "# Display shapes\n",
        "print('Test Image Shape:', test_img.shape)\n",
        "print('Predicted Image Shape:', predicted_label.shape)\n",
        "\n",
        "# Define plot configuration\n",
        "max_rows = 3\n",
        "max_cols = test_img.shape[2]\n",
        "fig, axes = plt.subplots(nrows=max_rows, ncols=max_cols, figsize=(20, 8))\n",
        "\n",
        "# Plot images\n",
        "for idx in range(max_cols):\n",
        "    axes[0, idx].axis(\"off\")\n",
        "    axes[0, idx].set_title('Test Image ' + str(idx+1))\n",
        "    axes[0, idx].imshow(test_img[:, :, idx], cmap=\"gray\")\n",
        "\n",
        "for idx in range(max_cols):\n",
        "    axes[1, idx].axis(\"off\")\n",
        "    axes[1, idx].set_title('Test Prediction ' + str(idx+1))\n",
        "    axes[1, idx].imshow(predicted_images[:, :, idx], cmap=\"gray\")\n",
        "\n",
        "for idx in range(max_cols):\n",
        "    axes[2, idx].axis(\"off\")\n",
        "    axes[2, idx].set_title('Train Label ' + str(idx+1))\n",
        "    axes[2, idx].imshow(predicted_label[:, :, idx], cmap=\"gray\")\n",
        "\n",
        "# Adjust subplot spacing\n",
        "plt.subplots_adjust(wspace=.1, hspace=.4)\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
